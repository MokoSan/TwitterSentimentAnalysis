{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two datasets we will be dealing with are the following:\n",
    "\n",
    "1. __Trump's Tweets__: Starting from late 2016 till April 2018. \n",
    "2. __SPY's Historical Price__: The movements of the SPY within the same time period.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Trump's Tweets\n",
    "import re\n",
    "import tweepy\n",
    "import csv\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer    \n",
    "\n",
    "# For SPY Data\n",
    "from datetime import datetime\n",
    "from pandas import DataFrame\n",
    "import pandas_datareader.data as dr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Trump's Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Credentials from Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables that contains the user credentials to access Twitter API \n",
    "ACCESS_TOKEN        = 'Nothing'\n",
    "ACCESS_TOKEN_SECRET = 'to'\n",
    "CONSUMER_KEY        = 'see'\n",
    "CONSUMER_SECRET     = 'here.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authentication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auth(): \n",
    "    oauth = tweepy.OAuthHandler( CONSUMER_KEY, CONSUMER_SECRET )\n",
    "    oauth.set_access_token( ACCESS_TOKEN, ACCESS_TOKEN_SECRET ) \n",
    "    return oauth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting All Tweets for Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 tweets downloaded so far.\n",
      "600 tweets downloaded so far.\n",
      "800 tweets downloaded so far.\n",
      "997 tweets downloaded so far.\n",
      "1197 tweets downloaded so far.\n",
      "1397 tweets downloaded so far.\n",
      "1596 tweets downloaded so far.\n",
      "1796 tweets downloaded so far.\n",
      "1996 tweets downloaded so far.\n",
      "2196 tweets downloaded so far.\n",
      "2396 tweets downloaded so far.\n",
      "2595 tweets downloaded so far.\n",
      "2795 tweets downloaded so far.\n",
      "2995 tweets downloaded so far.\n",
      "3195 tweets downloaded so far.\n",
      "3240 tweets downloaded so far.\n",
      "3240 tweets downloaded so far.\n"
     ]
    }
   ],
   "source": [
    "def get_all_tweets( screen_name ):\n",
    "    api = tweepy.API( auth() )\n",
    "    all_tweets = []\n",
    "\n",
    "    # Get the 200 Most Recent Tweets.\n",
    "    new_tweets = api.user_timeline( screen_name = screen_name, \n",
    "                                    count       = 200 )\n",
    "    all_tweets.extend( new_tweets )\n",
    "    \n",
    "    # Save the id of the oldest tweet less one\n",
    "    oldest_tweet_id = all_tweets[ -1 ].id - 1\n",
    "\n",
    "    # Let's get the most recent 4000 tweets. \n",
    "    while len( new_tweets ) > 0:\n",
    "        \n",
    "        # All Subsequent requests use the max_id param to prevent duplicates\n",
    "        new_tweets = api.user_timeline( screen_name = screen_name, \n",
    "                                        count       = 200,\n",
    "                                        max_id      = oldest_tweet_id, \n",
    "                                        tweet_mode  = 'extended' ) \n",
    "        \n",
    "        all_tweets.extend( new_tweets )\n",
    "        \n",
    "        # Update the id of the oldest tweet less one\n",
    "        oldest_tweet_id = all_tweets[ -1 ].id - 1\n",
    "        \n",
    "        print( f'{ len(all_tweets)} tweets downloaded so far.') \n",
    "        \n",
    "    return all_tweets\n",
    "\n",
    "donald_tweets = get_all_tweets( 'realDonaldTrump' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Looks like OPEC is at it again. With record amounts of Oil all over the '\n",
      " 'place, including the fully loaded ships at… https://t.co/l5MMjmtI14',\n",
      " 'Nancy Pelosi is going absolutely crazy about the big Tax Cuts given to the '\n",
      " 'American People by the Republicans...got… https://t.co/0REgmJNMqT',\n",
      " 'So exciting! I have agreed to be the Commencement Speaker at our GREAT Naval '\n",
      " 'Academy on May 25th in Annapolis, Mary… https://t.co/L9iZ6RS3ft',\n",
      " 'So General Michael Flynn’s life can be totally destroyed while Shadey James '\n",
      " 'Comey can Leak and Lie and make lots of… https://t.co/q1lyKyyeYI',\n",
      " 'James Comey Memos just out and show clearly that there was NO COLLUSION and '\n",
      " 'NO OBSTRUCTION. Also, he leaked classif… https://t.co/YfMYBrTkza']\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "# Let's print the text of the first 5 tweets.\n",
    "pprint.pprint( [ t.text  for t in donald_tweets[ : 5 ]] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tranforming the Tweets  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Helper Functions__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "def analyze_sentiment( input_tweet ):\n",
    "    return sid.polarity_scores( input_tweet )\n",
    "\n",
    "def clean_tweet( input_tweet ):\n",
    "    return ' '.join(re.sub( \"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\n",
    "                            \" \", \n",
    "                            input_tweet ).split() )\n",
    "\n",
    "def get_tweet_text( input_tweet ):\n",
    "    text = \"\"\n",
    "\n",
    "    if hasattr( input_tweet, 'full_text' ):\n",
    "        return clean_tweet( input_tweet.full_text )\n",
    "\n",
    "    elif hasattr( input_tweet, 'fulltext' ):\n",
    "        return clean_tweet( input_tweet.fulltext )\n",
    "\n",
    "    elif hasattr( input_tweet, 'text' ):\n",
    "        return clean_tweet( input_tweet.text )\n",
    "\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Tranformation Logic__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Created At</th>\n",
       "      <th>Cleaned Tweet</th>\n",
       "      <th>Sentiment Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-04-20</td>\n",
       "      <td>Looks like OPEC is at it again With record amo...</td>\n",
       "      <td>0.3612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-04-20</td>\n",
       "      <td>Nancy Pelosi is going absolutely crazy about t...</td>\n",
       "      <td>-0.5984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-04-20</td>\n",
       "      <td>So exciting I have agreed to be the Commenceme...</td>\n",
       "      <td>0.8931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-04-20</td>\n",
       "      <td>So General Michael Flynn s life can be totally...</td>\n",
       "      <td>-0.7089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-04-20</td>\n",
       "      <td>James Comey Memos just out and show clearly th...</td>\n",
       "      <td>-0.6669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Created At                                      Cleaned Tweet  \\\n",
       "0  2018-04-20  Looks like OPEC is at it again With record amo...   \n",
       "1  2018-04-20  Nancy Pelosi is going absolutely crazy about t...   \n",
       "2  2018-04-20  So exciting I have agreed to be the Commenceme...   \n",
       "3  2018-04-20  So General Michael Flynn s life can be totally...   \n",
       "4  2018-04-20  James Comey Memos just out and show clearly th...   \n",
       "\n",
       "   Sentiment Score  \n",
       "0           0.3612  \n",
       "1          -0.5984  \n",
       "2           0.8931  \n",
       "3          -0.7089  \n",
       "4          -0.6669  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform_tweets( input_tweets ):\n",
    "    output_tweets = [] \n",
    "        \n",
    "    for t in donald_tweets:\n",
    "        compound_value = 0\n",
    "        text           = get_tweet_text( t )\n",
    "        \n",
    "        if ( text == None ):\n",
    "            print( f'No text found for: User: {t.user.name} Tweet @ {t.created_at}')\n",
    "            continue\n",
    "        else:\n",
    "             compound_value = analyze_sentiment( text )[ 'compound' ] \n",
    "            \n",
    "        output_tweets.append( [ t.created_at.date(), text, compound_value ])\n",
    "    return DataFrame( data    = output_tweets, \n",
    "                      columns = [ \"Created At\", \n",
    "                                  \"Cleaned Tweet\", \n",
    "                                  \"Sentiment Score\" ])\n",
    "            \n",
    "transformed_tweets_df = transform_tweets( donald_tweets ) \n",
    "transformed_tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_tweets( transformed_tweets_df, file_path ):\n",
    "    transformed_tweets_df.to_csv( file_path )\n",
    " \n",
    "write_tweets( transformed_tweets_df = transformed_tweets_df, \n",
    "              file_path             = '../../data/realDonaldTrump_tweets.csv' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SPY Movements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Historical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting historical data for: SPY\n",
      "5y\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-04-20</th>\n",
       "      <td>196.8031</td>\n",
       "      <td>197.9234</td>\n",
       "      <td>196.7090</td>\n",
       "      <td>197.5468</td>\n",
       "      <td>92189481</td>\n",
       "      <td>SPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-21</th>\n",
       "      <td>198.3187</td>\n",
       "      <td>198.4976</td>\n",
       "      <td>196.9726</td>\n",
       "      <td>197.3115</td>\n",
       "      <td>72559831</td>\n",
       "      <td>SPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-22</th>\n",
       "      <td>197.6974</td>\n",
       "      <td>198.4882</td>\n",
       "      <td>196.6525</td>\n",
       "      <td>198.2811</td>\n",
       "      <td>78264616</td>\n",
       "      <td>SPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-23</th>\n",
       "      <td>197.8292</td>\n",
       "      <td>199.5143</td>\n",
       "      <td>197.6974</td>\n",
       "      <td>198.7800</td>\n",
       "      <td>102585942</td>\n",
       "      <td>SPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-24</th>\n",
       "      <td>199.2507</td>\n",
       "      <td>199.5425</td>\n",
       "      <td>198.7329</td>\n",
       "      <td>199.2412</td>\n",
       "      <td>61327387</td>\n",
       "      <td>SPY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                open      high       low     close     volume Name\n",
       "date                                                              \n",
       "2015-04-20  196.8031  197.9234  196.7090  197.5468   92189481  SPY\n",
       "2015-04-21  198.3187  198.4976  196.9726  197.3115   72559831  SPY\n",
       "2015-04-22  197.6974  198.4882  196.6525  198.2811   78264616  SPY\n",
       "2015-04-23  197.8292  199.5143  197.6974  198.7800  102585942  SPY\n",
       "2015-04-24  199.2507  199.5425  198.7329  199.2412   61327387  SPY"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def download_historical_prices_for_instrument( ticker ):\n",
    "    try:\n",
    "        now_time         = datetime.now()\n",
    "        print(f\"Getting historical data for: {ticker}\")\n",
    "        start_time       = datetime(now_time.year - 3, now_time.month , now_time.day)\n",
    "        stock_df         = dr.DataReader( ticker,'iex', start_time, now_time)\n",
    "        stock_df['Name'] = ticker\n",
    "        return stock_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f'Unable to get data for: {ticker} because of Error: {e} ')\n",
    "        \n",
    "spy_df = download_historical_prices_for_instrument( 'SPY' )\n",
    "spy_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
