{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition: Getting Tweet Sentiments And SPY Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SPY](https://static.seekingalpha.com/uploads/2017/8/12/34092875-1502537153708901.png \"SPY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two datasets I have decided to deal with are the following:\n",
    "\n",
    "* __Famous Political Leaders' Tweets__: Starting from late 2016 till April 2018. These Famous Political Leaders will include:\n",
    "    1. Donald Trump\n",
    "    2. Mike Pence\n",
    "    3. Paul Ryan\n",
    "  \n",
    "    \n",
    "* __Historical SPY Data__: The Price Range and other details of the SPY within the same time period are acquired using the Pandas Data Reader. The Price Range will be calculated by subtracting the __low__ price from the __high__ for a particular day.\n",
    "\n",
    "Once we have all this data independently, we will grouping each of the data by __day__. If a political leader has tweeted multiple times a day, the __average sentiment__ of that day will be taken into consideration. Subsequently, we will be joining the two day-by-day data for the SPY and Tweets after converting those into a Pandas Dataframe and then save the result in the form of a csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Libraries\n",
    "\n",
    "Let's start off by loading all the libraries used for the data acquisition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Twitter \n",
    "import re\n",
    "import tweepy\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# For SPY Data\n",
    "from datetime import datetime\n",
    "from pandas import DataFrame, to_numeric, to_datetime, Grouper, merge \n",
    "import pandas_datareader.data as dr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Famous Political Leaders' Tweets\n",
    " \n",
    "Our process to obtain the Political Leader's Tweets is as follows:\n",
    "\n",
    "* __Authentication__: We will first use the Tweepy library to authenticate ourselves to be able to use the API.  \n",
    "\n",
    "\n",
    "* __Getting the Tweets__: We will be going as far back as early 2017 to grab our Tweets for each of the Famous Political Leaders we have decided to get data from.  \n",
    " \n",
    "\n",
    "* __Sentiment Analysis of the Tweets__: We will be using NLTK's Vader Sentiment Analysis model to compute the sentiment analysis for all the tweets. This stage will involve cleaning the tweets that would involve removing any hyperlinks embedded in the tweet itself or RTs with the username.  \n",
    " \n",
    "\n",
    "* __Grouping Sentiment Score by Data__: Once the data is available and cleaned, we will be grouping the data by date which will produce an independent dataframe with the index as the Date and the average sentiment score as the only column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authentication\n",
    "\n",
    "It is fairly straight forward to get authenticated. We are simply using the Access token and Secret along with the Consumer key and Secret to return to us an authenticated Tweepy object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables that contains the user credentials to access Twitter API \n",
    "# The Keys were removed but kept here for completeness sake.\n",
    "ACCESS_TOKEN        = 'Nothing'\n",
    "ACCESS_TOKEN_SECRET = 'to'\n",
    "CONSUMER_KEY        = 'see'\n",
    "CONSUMER_SECRET     = 'here.'\n",
    "\n",
    "def auth(): \n",
    "    '''Function responsible for sending the correct Authorization for Twitter.\n",
    "    '''\n",
    "    oauth = tweepy.OAuthHandler( CONSUMER_KEY, CONSUMER_SECRET )\n",
    "    oauth.set_access_token( ACCESS_TOKEN, ACCESS_TOKEN_SECRET ) \n",
    "    return oauth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Tweets\n",
    "\n",
    "The tweet acquisition step involved batching the tweets from an API in chunks of 200 and subsequently keeping track of __when__ our last tweet was from using a tweet id. Our function to do so simply takes in a screen name and gets all the tweet's from the user's timeline including Retweets. We will get back quite the loaded object from the API from which we will just need the text of the tweet and date for our next step in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_tweets( screen_name ):\n",
    "    '''Function gets all the associated tweets linked with a Screen Name'''\n",
    "    api = tweepy.API( auth() )\n",
    "    all_tweets = []\n",
    "    print( f\"Getting Tweets for: {screen_name}\") \n",
    "\n",
    "    # Get the 200 Most Recent Tweets.\n",
    "    new_tweets = api.user_timeline( screen_name = screen_name, \n",
    "                                    count       = 200 )\n",
    "    all_tweets.extend( new_tweets )\n",
    "    \n",
    "    # Save the id of the oldest tweet less one\n",
    "    oldest_tweet_id = all_tweets[ -1 ].id - 1\n",
    "\n",
    "    # Let's get the most recent 4000 tweets. \n",
    "    while len( new_tweets ) > 0:\n",
    "        \n",
    "        # All Subsequent requests use the max_id param to prevent duplicates\n",
    "        new_tweets = api.user_timeline( screen_name = screen_name, \n",
    "                                        count       = 200,\n",
    "                                        max_id      = oldest_tweet_id, \n",
    "                                        tweet_mode  = 'extended' ) \n",
    "        \n",
    "        all_tweets.extend( new_tweets )\n",
    "        \n",
    "        # Update the id of the oldest tweet less one\n",
    "        oldest_tweet_id = all_tweets[ -1 ].id - 1\n",
    "        \n",
    "        print( f'{ len(all_tweets)} tweets downloaded so far.') \n",
    "        \n",
    "    return all_tweets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the Function with Donald Trump's Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Tweets for: realDonaldTrump\n",
      "400 tweets downloaded so far.\n",
      "600 tweets downloaded so far.\n",
      "800 tweets downloaded so far.\n",
      "997 tweets downloaded so far.\n",
      "1194 tweets downloaded so far.\n",
      "1394 tweets downloaded so far.\n",
      "1593 tweets downloaded so far.\n",
      "1793 tweets downloaded so far.\n",
      "1993 tweets downloaded so far.\n",
      "2193 tweets downloaded so far.\n",
      "2393 tweets downloaded so far.\n",
      "2592 tweets downloaded so far.\n",
      "2792 tweets downloaded so far.\n",
      "2992 tweets downloaded so far.\n",
      "3192 tweets downloaded so far.\n",
      "3207 tweets downloaded so far.\n",
      "3207 tweets downloaded so far.\n"
     ]
    }
   ],
   "source": [
    "donald_tweets = get_all_tweets( 'realDonaldTrump' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis of the Tweets\n",
    "\n",
    "This process starts by cleaning the text of the tweets by stripping off any URLs, non-alphanumeric characters and RT metadata embedded in a tweet. The Vader SentimentIntensityAnalyser is then subsequently used on this cleaned tweet data to give us back a dictionary with a polarity score out of which we consider the __compound__ polarity that is a combination of positive, neutral and negative sentiment scores; this number ranges from -1 to 1.  \n",
    "\n",
    "Our final output is a dataframe consisting of 2 columns: __date__ i.e. date of the tweet and __Sentiment Score__.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Helper Functions__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "def analyze_sentiment( input_tweet ):\n",
    "    '''Function returns the polarity scores for the input cleaned tweet.'''\n",
    "    return sid.polarity_scores( input_tweet )\n",
    "\n",
    "def clean_tweet( input_tweet ):\n",
    "    '''Function cleans the tweet by removing non-alphanumeric characters, hyperlinks, \n",
    "       RT metadata etc. \n",
    "    '''\n",
    "    return ' '.join(re.sub( \"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|RT @[\\w_]+:\",\n",
    "                            \" \", \n",
    "                            input_tweet ).split() )\n",
    "\n",
    "def get_tweet_text( input_tweet ):\n",
    "    '''Function gets the clean version of the text associated with a tweet. \n",
    "    '''\n",
    "    text = \"\"\n",
    "\n",
    "    if hasattr( input_tweet, 'full_text' ):\n",
    "        return clean_tweet( input_tweet.full_text )\n",
    "\n",
    "    elif hasattr( input_tweet, 'fulltext' ):\n",
    "        return clean_tweet( input_tweet.fulltext )\n",
    "\n",
    "    elif hasattr( input_tweet, 'text' ):\n",
    "        return clean_tweet( input_tweet.text )\n",
    "\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Cleaning and Transforming Tweets into a Dataframe__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_tweets( input_tweets, sentiment_score_col_name ):\n",
    "    '''Function transforms the tweet text into a sentiment score and saves \n",
    "       it in a dataframe\n",
    "    '''\n",
    "    output_tweets = [] \n",
    "        \n",
    "    for t in input_tweets:\n",
    "        compound_value = 0\n",
    "        text           = get_tweet_text( t )\n",
    "        \n",
    "        # Ignore cases where the text is not found.\n",
    "        if ( text == None ):\n",
    "            print( f'No text found for: User: {t.user.name} Tweet @ {t.created_at}')\n",
    "            continue\n",
    "        else:\n",
    "             compound_value = analyze_sentiment( text )[ 'compound' ] \n",
    "            \n",
    "        output_tweets.append( [ t.created_at.date(), compound_value ])\n",
    "        \n",
    "    df = DataFrame( data    = output_tweets, \n",
    "                    columns = [ \"date\",  \n",
    "                                sentiment_score_col_name ] )\n",
    "    df[ 'date' ] = to_datetime( df[ 'date' ])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the Transformation Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Sentiment Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-04-29</td>\n",
       "      <td>0.6444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-04-29</td>\n",
       "      <td>0.5719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-04-29</td>\n",
       "      <td>0.9042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-04-28</td>\n",
       "      <td>0.2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-04-28</td>\n",
       "      <td>-0.0083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  Sentiment Score\n",
       "0 2018-04-29           0.6444\n",
       "1 2018-04-29           0.5719\n",
       "2 2018-04-29           0.9042\n",
       "3 2018-04-28           0.2960\n",
       "4 2018-04-28          -0.0083"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donald_tweets_df = transform_tweets( donald_tweets, \n",
    "                                     \"Sentiment Score\" ) \n",
    "donald_tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Score Grouped by Date\n",
    "\n",
    "Once we have all the data for all days, we will need to squash the multiday twitter sentiment score into a single value to eventually key off the date only. We do this by using the mean of the multiple tweets per day to give us a singular compound mean value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_grouped_by_date( tweets_df ):\n",
    "    '''Function creates a new data frame with date as the index and the sentiment score \n",
    "       as a column.\n",
    "    '''\n",
    "    return tweets_df.groupby( Grouper( 'date' )).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the Grouping Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-29</th>\n",
       "      <td>0.706833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-28</th>\n",
       "      <td>0.241950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-27</th>\n",
       "      <td>0.322336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-26</th>\n",
       "      <td>0.537200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-25</th>\n",
       "      <td>0.339400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sentiment Score\n",
       "date                       \n",
       "2018-04-29         0.706833\n",
       "2018-04-28         0.241950\n",
       "2018-04-27         0.322336\n",
       "2018-04-26         0.537200\n",
       "2018-04-25         0.339400"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donald_sentiment_score_df = create_df_grouped_by_date( donald_tweets_df )\n",
    "donald_sentiment_score_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully forged the first few functions needed to easily get us the Twitter sentiment data. Our next step is to acquire data of the SPY and then merge the two dataframes together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historical SPY Data\n",
    "\n",
    "The process of getting the SPY data is fairly easy, we will be using the Pandas Data reader for this step starting from the end of 2016 to the present day.\n",
    "\n",
    "The process will consist of:\n",
    "* Acquiring the Historical SPY Data\n",
    "* Adding the Price Range to the Data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquiring the Historical SPY Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting historical data for: SPY\n",
      "2y\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-12-30</th>\n",
       "      <td>219.5765</td>\n",
       "      <td>219.6742</td>\n",
       "      <td>217.6223</td>\n",
       "      <td>218.4040</td>\n",
       "      <td>108998328</td>\n",
       "      <td>SPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-03</th>\n",
       "      <td>219.8794</td>\n",
       "      <td>220.6512</td>\n",
       "      <td>218.7496</td>\n",
       "      <td>220.0748</td>\n",
       "      <td>91366522</td>\n",
       "      <td>SPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>220.4461</td>\n",
       "      <td>221.5501</td>\n",
       "      <td>220.4363</td>\n",
       "      <td>221.3840</td>\n",
       "      <td>78744433</td>\n",
       "      <td>SPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05</th>\n",
       "      <td>221.0812</td>\n",
       "      <td>221.3840</td>\n",
       "      <td>220.3093</td>\n",
       "      <td>221.2082</td>\n",
       "      <td>78379012</td>\n",
       "      <td>SPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-06</th>\n",
       "      <td>221.3352</td>\n",
       "      <td>222.5272</td>\n",
       "      <td>220.7196</td>\n",
       "      <td>221.9996</td>\n",
       "      <td>71559922</td>\n",
       "      <td>SPY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                open      high       low     close     volume Name\n",
       "date                                                              \n",
       "2016-12-30  219.5765  219.6742  217.6223  218.4040  108998328  SPY\n",
       "2017-01-03  219.8794  220.6512  218.7496  220.0748   91366522  SPY\n",
       "2017-01-04  220.4461  221.5501  220.4363  221.3840   78744433  SPY\n",
       "2017-01-05  221.0812  221.3840  220.3093  221.2082   78379012  SPY\n",
       "2017-01-06  221.3352  222.5272  220.7196  221.9996   71559922  SPY"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def download_historical_prices_for_instrument( ticker ):\n",
    "    '''Function gets the historical data of a specified ticker.'''\n",
    "    try:\n",
    "        now_time         = datetime.now()\n",
    "        print(f\"Getting historical data for: {ticker}\")\n",
    "        start_time       = datetime(2016, 12 , 30)\n",
    "        stock_df         = dr.DataReader( ticker,'iex', start_time, now_time)\n",
    "        stock_df['Name'] = ticker\n",
    "        return stock_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f'Unable to get data for: {ticker} because of Error: {e} ')\n",
    "        \n",
    "spy_df = download_historical_prices_for_instrument( 'SPY' )\n",
    "spy_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the Price Range in the DataFrame\n",
    "\n",
    "The price range is simply the high price of the day minus the low price and is added as a new column to the Dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>Name</th>\n",
       "      <th>range</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-27</th>\n",
       "      <td>267.00</td>\n",
       "      <td>267.3400</td>\n",
       "      <td>265.50</td>\n",
       "      <td>266.56</td>\n",
       "      <td>57053647</td>\n",
       "      <td>SPY</td>\n",
       "      <td>1.8400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-26</th>\n",
       "      <td>264.79</td>\n",
       "      <td>267.2452</td>\n",
       "      <td>264.29</td>\n",
       "      <td>266.31</td>\n",
       "      <td>67731942</td>\n",
       "      <td>SPY</td>\n",
       "      <td>2.9552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-25</th>\n",
       "      <td>262.91</td>\n",
       "      <td>264.1300</td>\n",
       "      <td>260.85</td>\n",
       "      <td>263.63</td>\n",
       "      <td>103756753</td>\n",
       "      <td>SPY</td>\n",
       "      <td>3.2800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-24</th>\n",
       "      <td>267.73</td>\n",
       "      <td>267.9762</td>\n",
       "      <td>261.28</td>\n",
       "      <td>262.98</td>\n",
       "      <td>112885452</td>\n",
       "      <td>SPY</td>\n",
       "      <td>6.6962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-23</th>\n",
       "      <td>267.26</td>\n",
       "      <td>267.8900</td>\n",
       "      <td>265.35</td>\n",
       "      <td>266.57</td>\n",
       "      <td>65557954</td>\n",
       "      <td>SPY</td>\n",
       "      <td>2.5400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              open      high     low   close     volume Name   range\n",
       "date                                                                \n",
       "2018-04-27  267.00  267.3400  265.50  266.56   57053647  SPY  1.8400\n",
       "2018-04-26  264.79  267.2452  264.29  266.31   67731942  SPY  2.9552\n",
       "2018-04-25  262.91  264.1300  260.85  263.63  103756753  SPY  3.2800\n",
       "2018-04-24  267.73  267.9762  261.28  262.98  112885452  SPY  6.6962\n",
       "2018-04-23  267.26  267.8900  265.35  266.57   65557954  SPY  2.5400"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spy_df['range'] = ( to_numeric( spy_df['high'] ) - \n",
    "                    to_numeric( spy_df['low'] ))\n",
    "spy_df.sort_index( ascending=False, inplace= True ) \n",
    "spy_df.index = to_datetime( spy_df.index )\n",
    "spy_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Combining the Two DataFrames\n",
    "\n",
    "Now that we have the two data sets we wanted, our next step is to merge these into one data frame. We will use the __merge__ function from Pandas to \" inner join\" our Instrument dataframe with the Sentiment Score dataframe by using the Date key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_instrument_and_sentiment_dfs( instrument_df, \n",
    "                                          sentiment_score_df ):\n",
    "    '''Function returns a merged dataframe of the historical instrument information\n",
    "       and the sentiment score data frame.\n",
    "    '''\n",
    "    return merge( instrument_df, sentiment_score_df, \n",
    "                  how='inner', \n",
    "                  left_index=True, \n",
    "                  right_index=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the Combination of the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>Name</th>\n",
       "      <th>range</th>\n",
       "      <th>Sentiment Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-27</th>\n",
       "      <td>267.00</td>\n",
       "      <td>267.3400</td>\n",
       "      <td>265.50</td>\n",
       "      <td>266.56</td>\n",
       "      <td>57053647</td>\n",
       "      <td>SPY</td>\n",
       "      <td>1.8400</td>\n",
       "      <td>0.322336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-26</th>\n",
       "      <td>264.79</td>\n",
       "      <td>267.2452</td>\n",
       "      <td>264.29</td>\n",
       "      <td>266.31</td>\n",
       "      <td>67731942</td>\n",
       "      <td>SPY</td>\n",
       "      <td>2.9552</td>\n",
       "      <td>0.537200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-25</th>\n",
       "      <td>262.91</td>\n",
       "      <td>264.1300</td>\n",
       "      <td>260.85</td>\n",
       "      <td>263.63</td>\n",
       "      <td>103756753</td>\n",
       "      <td>SPY</td>\n",
       "      <td>3.2800</td>\n",
       "      <td>0.339400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-24</th>\n",
       "      <td>267.73</td>\n",
       "      <td>267.9762</td>\n",
       "      <td>261.28</td>\n",
       "      <td>262.98</td>\n",
       "      <td>112885452</td>\n",
       "      <td>SPY</td>\n",
       "      <td>6.6962</td>\n",
       "      <td>0.305412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-23</th>\n",
       "      <td>267.26</td>\n",
       "      <td>267.8900</td>\n",
       "      <td>265.35</td>\n",
       "      <td>266.57</td>\n",
       "      <td>65557954</td>\n",
       "      <td>SPY</td>\n",
       "      <td>2.5400</td>\n",
       "      <td>-0.265900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              open      high     low   close     volume Name   range  \\\n",
       "date                                                                   \n",
       "2018-04-27  267.00  267.3400  265.50  266.56   57053647  SPY  1.8400   \n",
       "2018-04-26  264.79  267.2452  264.29  266.31   67731942  SPY  2.9552   \n",
       "2018-04-25  262.91  264.1300  260.85  263.63  103756753  SPY  3.2800   \n",
       "2018-04-24  267.73  267.9762  261.28  262.98  112885452  SPY  6.6962   \n",
       "2018-04-23  267.26  267.8900  265.35  266.57   65557954  SPY  2.5400   \n",
       "\n",
       "            Sentiment Score  \n",
       "date                         \n",
       "2018-04-27         0.322336  \n",
       "2018-04-26         0.537200  \n",
       "2018-04-25         0.339400  \n",
       "2018-04-24         0.305412  \n",
       "2018-04-23        -0.265900  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donald_combined_df = combine_instrument_and_sentiment_dfs( spy_df,\n",
    "                                                           donald_sentiment_score_df )\n",
    "donald_combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Combined Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_combined_df( df_to_save, file_name ):\n",
    "    '''Function saves the dataframe as a csv to the specified filepath\n",
    "    '''\n",
    "    df_to_save.to_csv( f'./data/{file_name}.csv' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Saving of the Combined Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "realDonaldTrump.csv\r\n"
     ]
    }
   ],
   "source": [
    "save_combined_df( donald_combined_df, 'realDonaldTrump' )\n",
    "!ls ./data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalizing The Pipeline\n",
    "\n",
    "Now that we have all the independent and modular functions in place, we are going to run this prescribed pipeline for all 3 of our chosen political leaders to get us independent csvs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "political_twitter_handles = [ 'realDonaldTrump', 'SpeakerRyan', 'VP' ]\n",
    "\n",
    "def create_combined_df( screen_name, should_persist = False ):\n",
    "    '''Function creates a combined data frame of the screen name and SPY Historical Data\n",
    "    '''\n",
    "    try:\n",
    "        all_tweets         = get_all_tweets( screen_name )\n",
    "        transformed_tweets = transform_tweets( all_tweets, \n",
    "                                               f\"{screen_name} Vader Sentiment Score\" )\n",
    "        sentiment_score_df = create_df_grouped_by_date( transformed_tweets )\n",
    "        combined_df        = combine_instrument_and_sentiment_dfs( spy_df, \n",
    "                                                                   sentiment_score_df )\n",
    "        if ( should_persist ):\n",
    "            save_combined_df( combined_df, screen_name )\n",
    "        return combined_df\n",
    "    \n",
    "    except Exception as e :\n",
    "        print ( f'Error while getting the sentiment score for: {screen_name}: {e}')\n",
    "\n",
    "def get_and_save_sentiment_score_for_all():\n",
    "    return {  p : create_combined_df( p, True ) for p in political_twitter_handles }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting and Saving All Tweets \n",
    "\n",
    "Let's run our entire pipeline for all the decided political leaders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Tweets for: realDonaldTrump\n",
      "400 tweets downloaded so far.\n",
      "600 tweets downloaded so far.\n",
      "800 tweets downloaded so far.\n",
      "997 tweets downloaded so far.\n",
      "1194 tweets downloaded so far.\n",
      "1394 tweets downloaded so far.\n",
      "1593 tweets downloaded so far.\n",
      "1793 tweets downloaded so far.\n",
      "1993 tweets downloaded so far.\n",
      "2193 tweets downloaded so far.\n",
      "2393 tweets downloaded so far.\n",
      "2592 tweets downloaded so far.\n",
      "2792 tweets downloaded so far.\n",
      "2992 tweets downloaded so far.\n",
      "3192 tweets downloaded so far.\n",
      "3207 tweets downloaded so far.\n",
      "3207 tweets downloaded so far.\n",
      "Getting Tweets for: SpeakerRyan\n",
      "400 tweets downloaded so far.\n",
      "600 tweets downloaded so far.\n",
      "800 tweets downloaded so far.\n",
      "1000 tweets downloaded so far.\n",
      "1199 tweets downloaded so far.\n",
      "1399 tweets downloaded so far.\n",
      "1599 tweets downloaded so far.\n",
      "1799 tweets downloaded so far.\n",
      "1999 tweets downloaded so far.\n",
      "2199 tweets downloaded so far.\n",
      "2399 tweets downloaded so far.\n",
      "2598 tweets downloaded so far.\n",
      "2798 tweets downloaded so far.\n",
      "2998 tweets downloaded so far.\n",
      "3197 tweets downloaded so far.\n",
      "3236 tweets downloaded so far.\n",
      "3236 tweets downloaded so far.\n",
      "Getting Tweets for: VP\n",
      "400 tweets downloaded so far.\n",
      "600 tweets downloaded so far.\n",
      "800 tweets downloaded so far.\n",
      "1000 tweets downloaded so far.\n",
      "1200 tweets downloaded so far.\n",
      "1400 tweets downloaded so far.\n",
      "1600 tweets downloaded so far.\n",
      "1800 tweets downloaded so far.\n",
      "2000 tweets downloaded so far.\n",
      "2200 tweets downloaded so far.\n",
      "2400 tweets downloaded so far.\n",
      "2600 tweets downloaded so far.\n",
      "2800 tweets downloaded so far.\n",
      "3000 tweets downloaded so far.\n",
      "3200 tweets downloaded so far.\n",
      "3211 tweets downloaded so far.\n",
      "3211 tweets downloaded so far.\n"
     ]
    }
   ],
   "source": [
    "all_sentiments = get_and_save_sentiment_score_for_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
